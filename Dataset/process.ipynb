{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6800a0-d6ee-4124-995e-bfa080170fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a2e48d8-b0f9-4be1-9f57-fd341ab796e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where label is 1:  366\n",
      "Number of rows where is_generated is 1:  672446\n",
      "        source  target  label  timestamp  is_generated\n",
      "0            1       1      0          0             0\n",
      "1            2       2      0          0             0\n",
      "2            3       2      0          0             0\n",
      "3            4       3      0          0             0\n",
      "4            5       4      0          0             0\n",
      "...        ...     ...    ...        ...           ...\n",
      "672441     123      25      0          5             0\n",
      "672442    4556       6      0          5             0\n",
      "672443    1071     129      0          5             0\n",
      "672444      10       8      0          5             0\n",
      "672445    3687     119      0          5             0\n",
      "\n",
      "[672080 rows x 5 columns]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "Total unique elements: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_name = 'reddit'\n",
    "\n",
    "df = pd.read_csv(f'{data_name}.csv', header=None)\n",
    "df.columns = ['source', 'target', 'timestamp', 'label']\n",
    "df = df.sort_values(by='timestamp')\n",
    "df['timestamp'] = pd.qcut(df['timestamp'], q=6, labels=False)\n",
    "df = df.reindex(columns=['source', 'target', 'label', 'timestamp'])\n",
    "df['is_generated'] = 0\n",
    "label_0_count = df[df['label'] == 1].shape[0]\n",
    "# 统计'is_generated'的数量\n",
    "is_generated_count = df[df['is_generated'] == 0].shape[0]\n",
    "print(\"Number of rows where label is 1: \", label_0_count)\n",
    "print(\"Number of rows where is_generated is 1: \", is_generated_count)\n",
    "# df[df['label'] <= 3]['timestamp'] = 3\n",
    "# df[df['label'] >= 8]['timestamp'] = 8\n",
    "# df['timestamp'] -= 3\n",
    "print(df[df['label'] == 0])\n",
    "print(df[df['label'] == 0]['timestamp'].unique())\n",
    "print(df[df['label'] == 1]['timestamp'].unique())\n",
    "\n",
    "unique_elements = pd.concat([df['source'], df['target']]).unique()\n",
    "print(\"Total unique elements:\", len(unique_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "890d7d33-2fbc-4e70-b57c-8319e4e97c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对原始数据进行训练/测试集切割\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 对训练集进一步切割，获取验证集\n",
    "train, valid = train_test_split(train, test_size=0.25, random_state=42)\n",
    "\n",
    "df_all = pd.concat([train, valid, test])\n",
    "\n",
    "all_nodes = set(train['source'].tolist())\n",
    "\n",
    "# 找到所有的时间戳子集\n",
    "timestamps = train['timestamp'].unique()\n",
    "\n",
    "# 遍历每个时间戳子集\n",
    "for timestamp_subset in timestamps:\n",
    "    # 找到在这个子集中存在的节点\n",
    "    subset_nodes = set(train[train['timestamp'] == timestamp_subset]['source'].tolist())\n",
    "\n",
    "    # 找到在全集上存在但不在子集中的节点\n",
    "    nodes_to_add = all_nodes - subset_nodes\n",
    "\n",
    "    # 只选择一半的节点来添加\n",
    "    num_nodes_to_add = len(nodes_to_add)\n",
    "    nodes_to_add = list(nodes_to_add)[:num_nodes_to_add]\n",
    "\n",
    "    # 为这些节点生成新的边\n",
    "    new_edges = []\n",
    "    for node_to_add in nodes_to_add:\n",
    "        # 随机选择一个在子集中的节点来与新添加的节点创建连接\n",
    "        existing_node_id = random.choice(list(subset_nodes))\n",
    "        new_edges.append([node_to_add, existing_node_id, 1, timestamp_subset, 1])\n",
    "\n",
    "    new_edges_df = pd.DataFrame(new_edges, columns=['source', 'target', 'label', 'timestamp', 'is_generated'])\n",
    "    df_all=pd.concat([df_all, new_edges_df], ignore_index=True)\n",
    "    train = pd.concat([train, new_edges_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c6545a-8ba7-49d8-9d81-7da0edd71156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_txt(df,type_):\n",
    "    # 根据\"timestamp\"的值拆分DataFrame为10个子DataFrame\n",
    "    grouped = df.groupby('timestamp')\n",
    "\n",
    "    # 创建并命名子DataFrame\n",
    "    sub_dataframes = [group for _, group in grouped]\n",
    "    sub_dataframe_names = [f'layer_{timestamp}' for timestamp, _ in grouped]\n",
    "\n",
    "    # 将子DataFrame与对应的名称关联起来\n",
    "    sub_dataframe_dict = dict(zip(sub_dataframe_names, sub_dataframes))\n",
    "\n",
    "    # 循环遍历每个层次的子DataFrame，将数据根据\"label\"的值分为正负样本\n",
    "    for name, sub_df in sub_dataframe_dict.items():\n",
    "        # print(sub_df)\n",
    "        pos_df = sub_df[sub_df['label'] == 0]\n",
    "        neg_df = sub_df[sub_df['label'] == 1]\n",
    "        layer = int(name[-1])+1\n",
    "        \n",
    "            # 将负样本数据写入文件\n",
    "        with open(f\"./{data_name}/{layer}_{type_}_neg.txt\", 'w') as neg_file:\n",
    "            for _, row in neg_df.iterrows():\n",
    "                neg_file.write(f\"{row['source']} {row['target']}\\n\")\n",
    "\n",
    "        # 将正样本数据写入文件\n",
    "        with open(f\"./{data_name}/{layer}_{type_}_pos.txt\", 'w') as pos_file:\n",
    "            for _, row in pos_df.iterrows():\n",
    "                pos_file.write(f\"{row['source']} {row['target']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb54d3e8-9d80-4c23-a6c5-9c62b1ebe86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_txt(train,'train')\n",
    "to_txt(valid,'valid')\n",
    "to_txt(test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb29b6b-5a59-482f-af76-10a6dc3c0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc8c9e-a053-4b58-862b-7eb1e7a4aa46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
